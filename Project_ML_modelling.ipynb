{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TODO:\n",
    "Make function that works with different train-test, different scaling, and different balancing\n",
    "Output: Descriptive dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're inserting random value column as measure of feature importance. If a feature has less score that this random generated column, it's a sign of its poor importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = [random.random() for i in range(len(df_encoded))]\n",
    "\n",
    "df_encoded['random'] = rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "nr = NearMiss()\n",
    "X, y = nr.fit_sample(X, y)\n",
    "\n",
    "print(f'Resampled dataset shape X: {len(X)}, Y: {len(y)}')\n",
    "\n",
    "sns.countplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle=True, stratify= y,\n",
    "                                                   random_state = 41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the train and test data in X training values and target column.\n",
    "\n",
    "With shuffle, we set whether or not to shuffle the data before splitting (Default True).\n",
    "With stratify, we choose to split the data stritifying via labels (Default None)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling allows us to standarize the numerical values of our dataset, centering to the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scale = StandardScaler()\n",
    "\n",
    "X_train = std_scale.fit_transform(X_train)\n",
    "\n",
    "X_test = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T15:40:21.042898Z",
     "start_time": "2020-05-06T15:40:21.040556Z"
    }
   },
   "outputs": [],
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neighbors = 3\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = neighbors)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = knn.predict(X_test)\n",
    "y_pred_train = knn.predict(X_train)\n",
    "\n",
    "print(f1_score(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(roc_auc_score(y_test, y_pred_test))\n",
    "print(roc_curve(y_test, y_pred_test))\n",
    "\n",
    "\n",
    "\n",
    "# print('Test set score: {:.2f}'.format(np.mean(y_pred_train == y_train)))\n",
    "# print('Test set score: {:.2f}'.format(np.mean(y_pred_test == y_test)))\n",
    "\n",
    "## Todo: function to print results of the model. #Pretty!\n",
    "\n",
    "print(\"Training set accuracy: {:.3f}\".format(knn.score(X_train, y_train)))\n",
    "print(\"Test set accuracy: {:.3f}\".format(knn.score(X_test, y_test)))\n",
    "\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_test)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T15:40:30.476320Z",
     "start_time": "2020-05-06T15:40:30.473563Z"
    }
   },
   "outputs": [],
   "source": [
    "#description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T15:32:30.443563Z",
     "start_time": "2020-05-06T15:32:30.327110Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.linear'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5a0d78a9ffc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.linear'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = logreg.predict(X_train)\n",
    "y_pred_test = logreg.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(roc_auc_score(y_test, y_pred_test))\n",
    "print(roc_curve(y_test, y_pred_test))\n",
    "\n",
    "print('Test set score: {:.2f}'.format(np.mean(y_pred_train == y_train)))\n",
    "print('Test set score: {:.2f}'.format(np.mean(y_pred_test == y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfor = RandomForestClassifier()\n",
    "\n",
    "rfor.fit(X_train, y_train)\n",
    "\n",
    "rfor.score(X_test, y_test)\n",
    "\n",
    "f1_score(rfor.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're defining a function to visualize the most important features on our Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model, df):\n",
    "    names = df.columns[model.feature_importances_.argsort()]\n",
    "    model.feature_importances_.sort()\n",
    "    plt.figure(figsize=(10,15))\n",
    "    n_features = len(names)\n",
    "    plt.barh(range(n_features), np.sort(model.feature_importances_), align='center')\n",
    "    plt.yticks(np.arange(n_features), names)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(rfor, df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, rfor.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dectree = DecisionTreeClassifier()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, shuffle=True, \n",
    "                                                    stratify=y_res,\n",
    "                                                    random_state=41)\n",
    "\n",
    "dectree.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = dectree.predict(X_train)\n",
    "y_pred_test = dectree.predict(X_test)\n",
    "\n",
    "print(f'Classification report\\n\\n{classification_report(y_test, y_pred_test)}')\n",
    "\n",
    "plot_feature_importances(dectree, df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linearsvc = LinearSVC()\n",
    "linearsvc.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = linearsvc.predict(X_train)\n",
    "y_pred_test = linearsvc.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(roc_auc_score(y_test, y_pred_test))\n",
    "print(roc_curve(y_test, y_pred_test))\n",
    "\n",
    "print('Train set score: {:.2f}'.format(np.mean(y_pred_train == y_train)))\n",
    "print('Test set score: {:.2f}'.format(np.mean(y_pred_test == y_test)))\n",
    "\n",
    "print(f'\\nClssification report\\n{classification_report(y_test, y_pred_test)}')\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_test), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T15:38:30.059489Z",
     "start_time": "2020-05-06T15:38:30.057214Z"
    }
   },
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "naive_b = GaussianNB()\n",
    "\n",
    "naive_b.fit(X_train, y_train)\n",
    "\n",
    "naive_b.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = naive_b.predict(X_train)\n",
    "y_pred_test = naive_b.predict(X_test)\n",
    "\n",
    "print(f'Classification report\\n\\n{classification_report(y_test, y_pred_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
