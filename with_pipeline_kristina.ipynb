{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Balancing-data\" data-toc-modified-id=\"Balancing-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Balancing data</a></span></li><li><span><a href=\"#Splitting-to-train-and-test\" data-toc-modified-id=\"Splitting-to-train-and-test-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Splitting to train and test</a></span></li><li><span><a href=\"#Fitting-classifier\" data-toc-modified-id=\"Fitting-classifier-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Fitting classifier</a></span></li><li><span><a href=\"#Model-Selection\" data-toc-modified-id=\"Model-Selection-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model Selection</a></span></li><li><span><a href=\"#Grid-Search-for-RandomForestClassifier\" data-toc-modified-id=\"Grid-Search-for-RandomForestClassifier-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Grid Search for RandomForestClassifier</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T11:49:31.746908Z",
     "start_time": "2020-05-06T11:49:31.739797Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score, precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T11:38:55.330552Z",
     "start_time": "2020-05-06T11:38:55.324567Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T12:53:12.750904Z",
     "start_time": "2020-05-06T12:53:12.597656Z"
    }
   },
   "outputs": [],
   "source": [
    "df_encoded = pd.read_csv('data/df_encoded.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T12:49:43.064271Z",
     "start_time": "2020-05-06T12:49:43.040180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_4.0TrafficType</th>\n",
       "      <th>x0_5.0TrafficType</th>\n",
       "      <th>x0_6.0TrafficType</th>\n",
       "      <th>x0_8.0TrafficType</th>\n",
       "      <th>x0_9.0TrafficType</th>\n",
       "      <th>x0_10.0TrafficType</th>\n",
       "      <th>x0_11.0TrafficType</th>\n",
       "      <th>x0_13.0TrafficType</th>\n",
       "      <th>x0_20.0TrafficType</th>\n",
       "      <th>x0_99.0TrafficType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0             0.0                      0.0            0.0   \n",
       "1             0.0                      0.0            0.0   \n",
       "2             0.0                      0.0            0.0   \n",
       "3             0.0                      0.0            0.0   \n",
       "4             0.0                      0.0            0.0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0             1.0                 0.000000   \n",
       "1                     0.0             2.0                64.000000   \n",
       "2                     0.0             1.0                64.000000   \n",
       "3                     0.0             2.0                 2.666667   \n",
       "4                     0.0            10.0               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay  ...  x0_4.0TrafficType  \\\n",
       "0         0.20       0.20         0.0         0.0  ...                0.0   \n",
       "1         0.00       0.10         0.0         0.0  ...                0.0   \n",
       "2         0.20       0.20         0.0         0.0  ...                0.0   \n",
       "3         0.05       0.14         0.0         0.0  ...                1.0   \n",
       "4         0.02       0.05         0.0         0.0  ...                1.0   \n",
       "\n",
       "   x0_5.0TrafficType  x0_6.0TrafficType  x0_8.0TrafficType  x0_9.0TrafficType  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   x0_10.0TrafficType  x0_11.0TrafficType  x0_13.0TrafficType  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "\n",
       "   x0_20.0TrafficType  x0_99.0TrafficType  \n",
       "0                 0.0                 0.0  \n",
       "1                 0.0                 0.0  \n",
       "2                 0.0                 0.0  \n",
       "3                 0.0                 0.0  \n",
       "4                 0.0                 0.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T12:08:40.017041Z",
     "start_time": "2020-05-06T12:08:40.005094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12330, 59)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T11:44:57.322732Z",
     "start_time": "2020-05-06T11:44:57.314066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Administrative             float64\n",
       "Administrative_Duration    float64\n",
       "Informational              float64\n",
       "Informational_Duration     float64\n",
       "ProductRelated             float64\n",
       "ProductRelated_Duration    float64\n",
       "BounceRates                float64\n",
       "ExitRates                  float64\n",
       "PageValues                 float64\n",
       "SpecialDay                 float64\n",
       "AnyPage                    float64\n",
       "Visitor_isReturning        float64\n",
       "Revenue_enc                  int64\n",
       "Weekend_enc                  int64\n",
       "x0_AugMonth                float64\n",
       "x0_DecMonth                float64\n",
       "x0_FebMonth                float64\n",
       "x0_JulMonth                float64\n",
       "x0_JuneMonth               float64\n",
       "x0_MarMonth                float64\n",
       "x0_MayMonth                float64\n",
       "x0_NovMonth                float64\n",
       "x0_OctMonth                float64\n",
       "x0_SepMonth                float64\n",
       "x0_1.0OperatingSystems     float64\n",
       "x0_2.0OperatingSystems     float64\n",
       "x0_3.0OperatingSystems     float64\n",
       "x0_4.0OperatingSystems     float64\n",
       "x0_99.0OperatingSystems    float64\n",
       "x0_1.0Region               float64\n",
       "x0_2.0Region               float64\n",
       "x0_3.0Region               float64\n",
       "x0_4.0Region               float64\n",
       "x0_5.0Region               float64\n",
       "x0_6.0Region               float64\n",
       "x0_7.0Region               float64\n",
       "x0_8.0Region               float64\n",
       "x0_9.0Region               float64\n",
       "x0_1.0Browser              float64\n",
       "x0_2.0Browser              float64\n",
       "x0_4.0Browser              float64\n",
       "x0_5.0Browser              float64\n",
       "x0_6.0Browser              float64\n",
       "x0_8.0Browser              float64\n",
       "x0_10.0Browser             float64\n",
       "x0_99.0Browser             float64\n",
       "x0_1.0TrafficType          float64\n",
       "x0_2.0TrafficType          float64\n",
       "x0_3.0TrafficType          float64\n",
       "x0_4.0TrafficType          float64\n",
       "x0_5.0TrafficType          float64\n",
       "x0_6.0TrafficType          float64\n",
       "x0_8.0TrafficType          float64\n",
       "x0_9.0TrafficType          float64\n",
       "x0_10.0TrafficType         float64\n",
       "x0_11.0TrafficType         float64\n",
       "x0_13.0TrafficType         float64\n",
       "x0_20.0TrafficType         float64\n",
       "x0_99.0TrafficType         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T12:53:18.848210Z",
     "start_time": "2020-05-06T12:53:18.834011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape X: 12330, y: 12330\n"
     ]
    }
   ],
   "source": [
    "X = df_encoded.drop(columns=['Revenue_enc', 'PageValues'])\n",
    "y = df_encoded['Revenue_enc']\n",
    "\n",
    "print(f'Original dataset shape X: {len(X)}, y: {len(y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T12:53:52.565403Z",
     "start_time": "2020-05-06T12:53:51.940929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape X: 3816, y: 3816\n"
     ]
    }
   ],
   "source": [
    "nr = NearMiss()\n",
    "X_res, y_res = nr.fit_sample(X, y)\n",
    "\n",
    "X_res=pd.DataFrame(X_res, columns=X.columns) \n",
    "y_res=pd.Series(y_res) \n",
    "\n",
    "print(f'Resampled dataset shape X: {len(X_res)}, y: {len(y_res)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T12:54:08.220678Z",
     "start_time": "2020-05-06T12:54:08.201258Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.2, shuffle=True, stratify= y_res, random_state = 41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T12:54:11.391004Z",
     "start_time": "2020-05-06T12:54:11.384336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pipeline for transfromations, here I only add scaler, could be also missing value imputation\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T13:20:36.192005Z",
     "start_time": "2020-05-06T13:20:36.185881Z"
    }
   },
   "outputs": [],
   "source": [
    "# In our case all the columns are already numeric, but here we could have 'num' and 'cat'\n",
    "\n",
    "numeric_features = X_res.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a pipeline that combines the preprocessor created above with a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T13:11:28.348679Z",
     "start_time": "2020-05-06T13:11:28.341179Z"
    }
   },
   "outputs": [],
   "source": [
    "lsvc = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T13:11:29.259763Z",
     "start_time": "2020-05-06T13:11:29.177712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean=True,\n",
       "                                                                                  with_std=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  Index(['Administrative', 'Administrative_Duration', 'Informational',\n",
       "       'Informational_D...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T13:11:30.137540Z",
     "start_time": "2020-05-06T13:11:30.122642Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = lsvc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our pipeline for multiple classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T13:29:50.828398Z",
     "start_time": "2020-05-06T13:29:49.803570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                     weights='uniform')\n",
      "model score: 0.758\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n",
      "model score: 0.929\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "model score: 0.927\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "model score: 0.941\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    LinearSVC(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    ]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', classifier)])\n",
    "    pipe.fit(X_train, y_train)   \n",
    "    print(classifier)\n",
    "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T13:06:18.585371Z",
     "start_time": "2020-05-06T13:06:18.577387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T13:15:12.358490Z",
     "start_time": "2020-05-06T13:11:54.909585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__criterion': 'entropy', 'classifier__max_depth': 8, 'classifier__max_features': 'sqrt', 'classifier__n_estimators': 500}\n",
      "0.9393840104849279\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "    'classifier__n_estimators': [200, 500],\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'classifier__max_depth' : [4,5,6,7,8],\n",
    "    'classifier__criterion' :['gini', 'entropy']}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "CV = GridSearchCV(lsvc, param_grid, n_jobs= 1)\n",
    "                  \n",
    "CV.fit(X_train, y_train)  \n",
    "print(CV.best_params_)    \n",
    "print(CV.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
